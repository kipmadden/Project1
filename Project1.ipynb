{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dependencies, API key and set output file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "from scipy.stats import linregress\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "import os\n",
    "import gmaps\n",
    "\n",
    "# Import API key from a file that is ignored by Git (.gitignore file) so the key isn't exposed to the public\n",
    "from config import gkey\n",
    "\n",
    "# Configure gmaps\n",
    "gmaps.configure(api_key=gkey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store County Health Rankings Excel file results into DataFrame\n",
    "\n",
    "* Load the excel file imported from https://www.countyhealthrankings.org/app/texas/2019/measure/outcomes/144/description?sort=desc-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Status</th>\n",
       "      <th>Border Status</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Population</th>\n",
       "      <th>Life Expectancy</th>\n",
       "      <th>Quality of Life</th>\n",
       "      <th>% Smokers</th>\n",
       "      <th>% Adult Obese</th>\n",
       "      <th>Food Environment Index</th>\n",
       "      <th>...</th>\n",
       "      <th>Violent Crime Rate</th>\n",
       "      <th>Injury Deaths Rate</th>\n",
       "      <th>Air pollution - particulate matter - Average Daily PM2.5</th>\n",
       "      <th>Drinking water violations = Y/N</th>\n",
       "      <th>% Severe housing problems</th>\n",
       "      <th>% Driving alone to work</th>\n",
       "      <th>% Long commute - driving alone</th>\n",
       "      <th>Median Household Income</th>\n",
       "      <th># Homeownership</th>\n",
       "      <th>% Homeownership</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anderson</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Non-Border</td>\n",
       "      <td>208</td>\n",
       "      <td>57741</td>\n",
       "      <td>73.7738</td>\n",
       "      <td>93</td>\n",
       "      <td>18.465775</td>\n",
       "      <td>34.4</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>416.609</td>\n",
       "      <td>77.9572</td>\n",
       "      <td>9.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>15.4467</td>\n",
       "      <td>85.0671</td>\n",
       "      <td>26.8</td>\n",
       "      <td>42412.0</td>\n",
       "      <td>11748</td>\n",
       "      <td>70.9121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andrews</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Non-Border</td>\n",
       "      <td>100</td>\n",
       "      <td>17722</td>\n",
       "      <td>76.7568</td>\n",
       "      <td>9</td>\n",
       "      <td>13.337848</td>\n",
       "      <td>32.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>493.888</td>\n",
       "      <td>86.4983</td>\n",
       "      <td>7.3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>14.4292</td>\n",
       "      <td>79.8453</td>\n",
       "      <td>27.1</td>\n",
       "      <td>63451.0</td>\n",
       "      <td>3981</td>\n",
       "      <td>73.5452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Angelina</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Non-Border</td>\n",
       "      <td>159</td>\n",
       "      <td>87805</td>\n",
       "      <td>76.3368</td>\n",
       "      <td>216</td>\n",
       "      <td>18.282139</td>\n",
       "      <td>39.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>311.671</td>\n",
       "      <td>69.2417</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>16.1354</td>\n",
       "      <td>82.9497</td>\n",
       "      <td>16.3</td>\n",
       "      <td>45318.0</td>\n",
       "      <td>20424</td>\n",
       "      <td>66.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aransas</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Non-Border</td>\n",
       "      <td>171</td>\n",
       "      <td>25572</td>\n",
       "      <td>76.9126</td>\n",
       "      <td>195</td>\n",
       "      <td>15.659176</td>\n",
       "      <td>31.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>476.548</td>\n",
       "      <td>100.817</td>\n",
       "      <td>9.3</td>\n",
       "      <td>No</td>\n",
       "      <td>15.5992</td>\n",
       "      <td>81.396</td>\n",
       "      <td>27.7</td>\n",
       "      <td>46970.0</td>\n",
       "      <td>7039</td>\n",
       "      <td>73.8692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Archer</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Non-Border</td>\n",
       "      <td>178</td>\n",
       "      <td>8809</td>\n",
       "      <td>77.0395</td>\n",
       "      <td>45</td>\n",
       "      <td>14.030731</td>\n",
       "      <td>28.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>201.652</td>\n",
       "      <td>86.9187</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.1493</td>\n",
       "      <td>86.027</td>\n",
       "      <td>19.8</td>\n",
       "      <td>58311.0</td>\n",
       "      <td>2752</td>\n",
       "      <td>82.1247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     County Status Border Status Rank Population Life Expectancy  \\\n",
       "0  Anderson  Rural    Non-Border  208      57741         73.7738   \n",
       "1   Andrews  Rural    Non-Border  100      17722         76.7568   \n",
       "2  Angelina  Rural    Non-Border  159      87805         76.3368   \n",
       "3   Aransas  Urban    Non-Border  171      25572         76.9126   \n",
       "4    Archer  Urban    Non-Border  178       8809         77.0395   \n",
       "\n",
       "  Quality of Life  % Smokers  % Adult Obese Food Environment Index  ...  \\\n",
       "0              93  18.465775           34.4                      6  ...   \n",
       "1               9  13.337848           32.2                    5.8  ...   \n",
       "2             216  18.282139           39.8                    8.1  ...   \n",
       "3             195  15.659176           31.8                    6.1  ...   \n",
       "4              45  14.030731           28.2                    6.1  ...   \n",
       "\n",
       "   Violent Crime Rate  Injury Deaths Rate  \\\n",
       "0             416.609             77.9572   \n",
       "1             493.888             86.4983   \n",
       "2             311.671             69.2417   \n",
       "3             476.548             100.817   \n",
       "4             201.652             86.9187   \n",
       "\n",
       "   Air pollution - particulate matter - Average Daily PM2.5  \\\n",
       "0                                                9.9          \n",
       "1                                                7.3          \n",
       "2                                                9.8          \n",
       "3                                                9.3          \n",
       "4                                                8.5          \n",
       "\n",
       "   Drinking water violations = Y/N  % Severe housing problems  \\\n",
       "0                              Yes                    15.4467   \n",
       "1                              Yes                    14.4292   \n",
       "2                              Yes                    16.1354   \n",
       "3                               No                    15.5992   \n",
       "4                              Yes                    10.1493   \n",
       "\n",
       "   % Driving alone to work % Long commute - driving alone  \\\n",
       "0                  85.0671                           26.8   \n",
       "1                  79.8453                           27.1   \n",
       "2                  82.9497                           16.3   \n",
       "3                   81.396                           27.7   \n",
       "4                   86.027                           19.8   \n",
       "\n",
       "   Median Household Income  # Homeownership  % Homeownership  \n",
       "0                  42412.0            11748          70.9121  \n",
       "1                  63451.0             3981          73.5452  \n",
       "2                  45318.0            20424          66.0308  \n",
       "3                  46970.0             7039          73.8692  \n",
       "4                  58311.0             2752          82.1247  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_df = pd.read_excel('data/2019.xls', header=[0, 1], sheet_name='Ranked Measure Data')\n",
    "additional_df = pd.read_excel('data/2019.xls', header=[0, 1], sheet_name='Additional Measure Data')\n",
    "shane_df = pd.read_excel('data/Shane.xlsx', sheet_name='RVU')\n",
    "shane_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "('Unnamed: 0_level_0', 'FIPS') ('Unnamed: 0_level_0', 'FIPS')\n"
     ]
    }
   ],
   "source": [
    "add_col = additional_df.columns\n",
    "rank_col = ranked_df.columns\n",
    "pk = add_col[0]\n",
    "print(type(pk))\n",
    "print(rank_col[0],add_col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The column label 'Unnamed: 0_level_0' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-0b45c386a025>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranked_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0madditional_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    974\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 975\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    976\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1795\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1796\u001b[0m                     \u001b[0mlabel_axis_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_axis_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1797\u001b[1;33m                     \u001b[0mmulti_message\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmulti_message\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1798\u001b[0m                 )\n\u001b[0;32m   1799\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: The column label 'Unnamed: 0_level_0' is not unique.\nFor a multi-index, the label must be a tuple with elements corresponding to each level."
     ]
    }
   ],
   "source": [
    "df = pd.merge(ranked_df,additional_df, how='inner', on=pk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of latitudes and longitudes\n",
    "lat_range = (-90, 90)\n",
    "lng_range = (-180, 180)\n",
    "\n",
    "# List for holding lat_lngs and cities\n",
    "lat_lngs = []\n",
    "cities = []\n",
    "countries = []\n",
    "\n",
    "# Create a set of random lat and lng combinations and zip into a list of tuples\n",
    "lats = np.random.uniform(low=-90.000, high=90.000, size=1500)\n",
    "lngs = np.random.uniform(low=-180.000, high=180.000, size=1500)\n",
    "lat_lngs = zip(lats, lngs)\n",
    "\n",
    "# Identify nearest city for each lat, lng combination using the Citypy package to return a unique city and country code\n",
    "for lat_lng in lat_lngs:\n",
    "    city = citipy.nearest_city(lat_lng[0], lat_lng[1]).city_name\n",
    "    country = citipy.nearest_city(lat_lng[0], lat_lng[1]).country_code\n",
    "    \n",
    "    # If the city is unique, then add it to a our cities list\n",
    "    if city not in cities:\n",
    "        cities.append(city)\n",
    "        countries.append(country)\n",
    "\n",
    "# Combine the two lists into a list of tuples using the zip function\n",
    "city_country = zip(cities,countries)\n",
    "\n",
    "# Print the city count to confirm sufficient count ( Greater than 500 )\n",
    "print(len(cities))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform API Calls\n",
    "\n",
    "* Perform a weather check on each city using a series of successive API calls.\n",
    "* Include a print log of each city as it's being processed (with the city number and city name).\n",
    "* Export all the city data into a .csv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save config information\n",
    "url = \"http://api.openweathermap.org/data/2.5/weather?\"\n",
    "units = \"imperial\"\n",
    "\n",
    "# set up lists to hold reponse info\n",
    "city_id = []\n",
    "city_name = []\n",
    "country = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "weather_date = []\n",
    "temp = []\n",
    "humidity = []\n",
    "cloudiness = []\n",
    "wind_speed = []\n",
    "\n",
    "# Open file to write results of API calls - success or not into a txt file, as well as all data pulled into a csv\n",
    "myprintlog = open('weatherAPI_printlog.txt', 'w')\n",
    "myAPIdata = open('weatherAPI_data.csv', 'w')\n",
    "\n",
    "# Write header line for csv file\n",
    "myAPIdata.write(\"city_id,city_name,country,latitude,longitude,weather_date,temp,humidity,cloudiness,wind_speed\\n\")\n",
    "\n",
    "# Loop through the list of tuples of cities,country codes and perform a request for data on each\n",
    "for city,country_code in city_country:\n",
    "    query_url = f\"{url}appid={api_key}&q={city},{country_code}&units={units}\"\n",
    "    response = requests.get(query_url).json()\n",
    "\n",
    "    # Try to grab the temp,humidity,cloudiness and wind speed if they are available in the Weather API\n",
    "    # if the city is not found on the WeatherAPI site then the \"except\" will catch the error and the loop will\n",
    "    # continue to go through the rest of the city,country_codes in the city_country list\n",
    "    try:\n",
    "        # Create variables for each response item and format to desired datatype\n",
    "        cityID = int(response['id'])\n",
    "        cityName = response['name']\n",
    "        countryCode = response['sys']['country']\n",
    "        lat_val = response['coord']['lat']\n",
    "        lon_val = response['coord']['lon']\n",
    "        weatherDate = (datetime.fromtimestamp(response['dt'])).strftime('%m/%d/%y')\n",
    "        temperature = response['main']['temp']\n",
    "        humidity_val = response['main']['humidity']\n",
    "        cloudiness_val = response['clouds']['all']\n",
    "        windSpeed = response['wind']['speed']\n",
    "        \n",
    "        # Append retreived values to lists above using the variables created above\n",
    "        city_id.append(cityID)\n",
    "        city_name.append(cityName)\n",
    "        country.append(countryCode)\n",
    "        latitude.append(lat_val)\n",
    "        longitude.append(lon_val)\n",
    "        weather_date.append(weatherDate)\n",
    "        temp.append(temperature)\n",
    "        humidity.append(humidity_val)\n",
    "        cloudiness.append(cloudiness_val)\n",
    "        wind_speed.append(windSpeed)\n",
    "        \n",
    "        # Output line to terminal to mark progress and store it to a print log text file\n",
    "        print(f\"{cityName} with city ID:{cityID} was found in the Weathermap API\\n\")\n",
    "        myprintlog.write(f\"{cityName} with city ID:{cityID} was found in the Weathermap API\\n\")\n",
    "        \n",
    "        # Output all retreived values to a csv file\n",
    "        myAPIdata.write(f\"{cityID},{cityName},{countryCode},{lat_val},{lon_val},{weatherDate},\\\n",
    "            {temperature},{humidity_val},{cloudiness_val},{windSpeed}\\n\")\n",
    "        \n",
    "    # Handle exceptions for a city that is not available in the Weather API\n",
    "    except:\n",
    "        \n",
    "        print(f\"{city},{country_code} was not found in the Weathermap API\\n\")\n",
    "        myprintlog.write(f\"{city},{country_code} was not found in the Weathermap API\\n\")\n",
    "        \n",
    "        # Append null values so lists are all the same length (later we will remove nulls from dataframe)\n",
    "        city_id.append(None)\n",
    "        city_name.append(None)\n",
    "        country.append(None)\n",
    "        latitude.append(None)\n",
    "        longitude.append(None)\n",
    "        weather_date.append(None)\n",
    "        temp.append(None)\n",
    "        humidity.append(None)\n",
    "        cloudiness.append(None)\n",
    "        wind_speed.append(None)\n",
    "        pass\n",
    "    \n",
    "# Close the file handle after completion of the loop\n",
    "myprintlog.close()\n",
    "myAPIdata.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw Data to DataFrame\n",
    "* Display the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dictionary from the lists that we created above\n",
    "weather_dict = {\n",
    "    \"city_id\": city_id,\n",
    "    \"city_name\": city_name,\n",
    "    \"country\": country,\n",
    "    \"latitude\": latitude,\n",
    "    \"longitude\": longitude,\n",
    "    \"weather_date\": weather_date,\n",
    "    \"temp\": temp,\n",
    "    \"humidity\": humidity,\n",
    "    \"cloudiness\": cloudiness,\n",
    "    \"wind_speed\": wind_speed\n",
    "}\n",
    "\n",
    "# Use the dictionary to create a dataframe named weather_data\n",
    "weather_data = pd.DataFrame(weather_dict)\n",
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe that has only non-null values (so linear regression can be done later)\n",
    "# First drop the NaN values\n",
    "weather_data_values = weather_data.dropna()\n",
    "\n",
    "# Reset the index (it will have gaps in it where the NaN value rows have been deleted)\n",
    "weather_data_values = weather_data_values.reset_index(drop=True)\n",
    "\n",
    "# Change the datatype for the city_id field to an integer (it gets created as a float)\n",
    "weather_data_values['city_id'] = weather_data_values['city_id'].astype(int)\n",
    "#weather_data_values.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the Data as Scatterplots to discern any patterns\n",
    "\n",
    "We will build a series of scatter plots to showcase the following relationships:\n",
    "\n",
    "* Temperature (F) vs. Latitude\n",
    "* Humidity (%) vs. Latitude\n",
    "* Cloudiness (%) vs. Latitude\n",
    "* Wind Speed (mph) vs. Latitude\n",
    "\n",
    "\n",
    "Plots will be labeled with plot titles (including date of analysis) and axes labels and then\n",
    "saved to the figures folder as .pngs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Temperature Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build a scatter plot for Latitude vs.Temperature in Fahrenheit\n",
    "weatherDate = weather_data_values['weather_date'][0]\n",
    "plt.scatter(weather_data_values[\"latitude\"], weather_data_values[\"temp\"], marker=\"o\",edgecolors='black')\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(f\"City Latitude vs. Temperature {weatherDate}\")\n",
    "plt.ylabel(\"Temperature (Fahrenheit)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Figures/LatitudeVsTemperature.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Latitude vs. Temperature plot has an unexpected result. As you move north of the equator from a latitude of 0 to a latitude of 80 you see what appears to be a linear decrease in temperature from 70 degrees Fahrenheit to -40 degrees Fahrenheit from 20 degrees latitude to around 80 degrees latitude. \n",
    "\n",
    "However, we do not see much of a drop moving south of the equator from 0 degrees latitude to around -55 degrees latitude. One reason for this is that there are so few cities in the southern hemisphere, but that can't fully account for the observation since from 0 to -40 we don't see any reduction in temperature (although there are ample cities). This compare to moving from 0 to 40 degrees latitude, where we see around a 40 degree drop in temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Humidity Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for Latitude vs. Humidity\n",
    "plt.scatter(weather_data_values[\"latitude\"], weather_data_values[\"humidity\"], marker=\"o\",edgecolors='black')\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(f\"City Latitude vs. Humidity {weatherDate}\")\n",
    "plt.ylabel(\"Humidity (%)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Figures/LatitudeVsHumidity.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Latitude vs. Humidity plot does not seem to have a strong correlation to latitude. One can say however, that it appears more cities have a humidity above 60% than a humidity below 60%. It will be interesting to see if grouping by Northern vs. Southern Hemispheres will tease this cluster apart to reveal a trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Cloudiness Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for Latitude vs. Cloudiness\n",
    "plt.scatter(weather_data_values[\"latitude\"], weather_data_values[\"cloudiness\"], marker=\"o\",edgecolors='black')\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(f\"City Latitude vs. Cloudiness {weatherDate}\")\n",
    "plt.ylabel(\"Cloudiness (%)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Figures/LatitudeVsCloudiness.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Latitude vs. Cloudiness plot does not seem to have any correlation to latitude. One can say however, that there seems to be a collection of points across all latitudes at either 0%, 75% or 100% Cloudy. I'd be curious if this measure is subjective or objective. I'd expect a subjective assesment to yield more 0%,25%,50% and 100% observations. An objective assesment would have a more even distribution. Given the \"lines\" we see at discreet %Cloudiness levels across all latitudes, I'd guess this measure is a subjective measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latitude vs. Wind Speed Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a scatter plot for Latitude vs. Wind Speed\n",
    "plt.scatter(weather_data_values[\"latitude\"], weather_data_values[\"wind_speed\"], marker=\"o\",edgecolors='black')\n",
    "\n",
    "# Incorporate the other graph properties\n",
    "plt.title(f\"City Latitude vs. Wind Speed {weatherDate}\")\n",
    "plt.ylabel(\"Wind Speed (mph)\")\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"Figures/LatitudeVsWindSpeed.png\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Latitude vs. Wind Speed scatterplot suggests there is no correlation between Wind Speed and Latitude. One can say that regardless of latitude we see the vast majority of wind speed between 0-20 mph, with most of those falling into the 0-10 mph range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Scatterplots for the Northern vs. Southern Hemispheres\n",
    "\n",
    "Our next objective is to run linear regression on each relationship, only this time separating them into Northern Hemisphere (greater than or equal to 0 degrees latitude) and Southern Hemisphere (less than 0 degrees latitude). The scatterplots we will create are:\n",
    "\n",
    "* Northern Hemisphere - Temperature (F) vs. Latitude\n",
    "* Southern Hemisphere - Temperature (F) vs. Latitude\n",
    "* Northern Hemisphere - Humidity (%) vs. Latitude\n",
    "* Southern Hemisphere - Humidity (%) vs. Latitude\n",
    "* Northern Hemisphere - Cloudiness (%) vs. Latitude\n",
    "* Southern Hemisphere - Cloudiness (%) vs. Latitude\n",
    "* Northern Hemisphere - Wind Speed (mph) vs. Latitude\n",
    "* Southern Hemisphere - Wind Speed (mph) vs. Latitude\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to accept arguments and create a linear regression scatterplot\n",
    "\n",
    "This function will accept a number of arguments and return a linear regression scatterplot that saves a figure to the figure folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Create a function to create Linear Regression plots\n",
    "\n",
    "# Make a function that accepts a list of x values and y values, a description for the x and y axes,\n",
    "# a string that describes which hemisphere is being analyzed and a filename to use while saving the figure\n",
    "# and finally the x,y coordinates to create the annotation of the equation on the graph\n",
    "def make_lin_reg_plot(x_values,y_values,x_desc,y_desc,hemisphere,filename,x_ann,y_ann):\n",
    "    # Print out the r-squared value along with the plot.\n",
    "    (slope, intercept, rvalue, pvalue, stderr) = linregress(x_values, y_values)\n",
    "    regress_values = x_values * slope + intercept\n",
    "    line_eq = \"y = \" + str(round(slope,2)) + \"x + \" + str(round(intercept,2))\n",
    "    plt.scatter(x_values,y_values,edgecolors='black')\n",
    "    plt.plot(x_values,regress_values,\"r-\")\n",
    "    plt.title(f\"{hemisphere}-\\nCity {x_desc} vs. {y_desc} {weatherDate}\")\n",
    "    plt.annotate(line_eq,(x_ann,y_ann),fontsize=15,color=\"red\")\n",
    "    plt.xlabel(x_desc)\n",
    "    plt.ylabel(y_desc)\n",
    "    print(f\"The r-squared is: {rvalue}\")\n",
    "    print(line_eq)\n",
    "    plt.savefig(f'Figures/{filename}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create subset dataframes for Northern and Southern Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Northern and Southern Hemisphere DataFrames\n",
    "# store the boolean criteria in a variable to pass to the dataframe indexing function\n",
    "crit_north = weather_data_values.latitude >= 0\n",
    "crit_south = weather_data_values.latitude < 0\n",
    "\n",
    "# Create the north and south hemisphere dataframes using boolean indexing from the criteria from above \n",
    "north_weather = weather_data_values[crit_north]\n",
    "south_weather = weather_data_values[crit_south]\n",
    "\n",
    "# The indexes will not be continuous so they need to be reset with the drop=True argument so we don't make\n",
    "# the prior index as a column\n",
    "north_weather = north_weather.reset_index(drop=True)\n",
    "south_weather = south_weather.reset_index(drop=True)\n",
    "#north_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Northern Hemisphere - Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_lin_reg_plot(north_weather[\"latitude\"],north_weather[\"temp\"],\\\n",
    "                  'Latitude','Temperature (Fahrenheit)','Northern Hemisphere',\\\n",
    "                 'NorthHemiLatVsTemp.png',6,-20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatterplot with linear regression has and r-squared value of -0.87, so there is a strong negative linear relationship between decreasing latitude and decreasing temperature in the Northern Hemisphere. This means 87% of the variance is explained by this linear model, which is very good. Keep in mind that if the model explained 100% of the variance, all the points would have to be on the curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Southern Hemisphere - Temp vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(south_weather[\"latitude\"],south_weather[\"temp\"],\\\n",
    "                  'Latitude',f'Temperature (Fahrenheit)','Southern Hemisphere',\\\n",
    "                 'SouthHemiLatVsTemp.png',-50,55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot shows a weaker relationship between temperature and latitude in the Southern Hemisphere, with an r-squared value of 0.42. This means the linear curve fit can only account for 42% of the variance seen in the data, leaving the majority of the variance unexplained by the equation of the line y = 0.25x + 80.05. So, although there seems to be a correlation it is weak at best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Northern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(north_weather[\"latitude\"],north_weather[\"humidity\"],\\\n",
    "                  'Latitude',f'Humidity (%)','Northern Hemisphere',\\\n",
    "                 'NorthHemiLatVsHumidity.png',40,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatter plot shows a very weak relationship between latitude and humidity in the Northern Hemisphere with an r-squared value of 0.29. This means the linear curve fit can only account for 29% of the variance seen in the data, leaving the vast majority of the variance unexplained by the equation of the line y = 0.3x + 65.17. So, although there seems to be a correlation it is very weak and I would conclude there is little correlation between latitude and humidity in the Northern Hemisphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Southern Hemisphere - Humidity (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(south_weather[\"latitude\"],south_weather[\"humidity\"],\\\n",
    "                  'Latitude',f'Humidity (%)','Southern Hemisphere',\\\n",
    "                 'SouthHemiLatVsHumidity.png',-30,20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Southern Hemisphere there is a weak correlation between latitude and humidity. The linear regression has an r-squared value of 0.42 - meaning 42% of the variance in the data is explained by the curve fit. This is not a strong correlation, but rather a weak one, but we can't say there is no correlation. Other factors play the majority of the role in the change in humidity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Northern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(north_weather[\"latitude\"],north_weather[\"cloudiness\"],\\\n",
    "                  'Latitude',f'Cloudiness (%)','Northern Hemisphere',\\\n",
    "                 'NorthHemiLatVsCloudiness.png',40,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Northern Hemisphere there does not seem to be a significant correlation between latitude and cloudiness. The linear regression curve fit yields an equation of the line with an r-squared value of only 0.185 - meaning the linear equation of the line only explains 18.5% of the variance seen. Visually we can confirm what the math indicates - that there is really no correlation between the latitude and cloudiness in the Northern Hemisphere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Southern Hemisphere - Cloudiness (%) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(south_weather[\"latitude\"],south_weather[\"cloudiness\"],\\\n",
    "                  'Latitude',f'Cloudiness (%)','Southern Hemisphere',\\\n",
    "                 'SouthHemiLatVsCloudiness.png',-55,6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Southern Hemisphere, latitude weakly correlates with cloudiness with and equation of the linear regression yielding an r-squared value of 0.39 - or 39% of the variance of the observed data can be accounted for by the equation of the linear regression line. This is a weak correlation. By looking at the data I would not have guessed that we would even see a number that high - I'd guess it was an r-squared in the teens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Northern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(north_weather[\"latitude\"],north_weather[\"wind_speed\"],\\\n",
    "                  'Latitude',f'Wind Speed (mph)','Northern Hemisphere',\\\n",
    "                 'NorthHemiLatVsWindSpeed.png',10,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is almost no correlation between latitude and wind speed in the Northern Hemisphere. The linear regression gives us the weakest r-squared value of all the scatterplots we have examined thus far - 0.07. Only 7% of the variance can be accounted for by the equation of the line - so for all practical purposes there isn't a linear correlation between these two factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Southern Hemisphere - Wind Speed (mph) vs. Latitude Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_lin_reg_plot(south_weather[\"latitude\"],south_weather[\"wind_speed\"],\\\n",
    "                  'Latitude',f'Wind Speed (mph)','Southern Hemisphere',\\\n",
    "                 'SouthHemiLatVsWindSpeed.png',-30,30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Southern Hemisphere we see a much stronger correlation between latitude and wind speed with an r-squared value of -0.41. But this is still weak and it is saying that the majority (59%) of the variance cannot be explained by the linear regression curve fit. I would feel confident about saying that there is a weak correlation between latitude and wind speed in the Southern Hemisphere - as you move away from the equator towards the south pole wind speed increase. Since there are so few cities south of -50 degrees latitude, this also may be a function of sparse data. It is well know that the south pole is a \"permanent storm\". I would expect that if there were cities in that region of the world that they would be incredibly windy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
